{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Geracao de Textos com RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "34XSvWs9wQT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import time, math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L37XwgfLEA5E",
        "colab_type": "code",
        "outputId": "4bd533fd-3869-48a8-8c04-edaa72e07501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "# Ler um arquivo em texto puro contendo o conteúdo a ser aprendido\n",
        "file = open('lfv_texts_plain.txt').read()\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)\n",
        "\n",
        "all_characters = ''.join(set(file))\n",
        "n_characters = len(all_characters)\n",
        "\n",
        "print(all_characters, n_characters)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-487c8e31f783>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lfv_texts_plain.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfile_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'file_len ='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_characters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lfv_texts_plain.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wewNlQiRf69N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chunk_len = 200\n",
        "\n",
        "# Gera um pedaço aleatório de texto com o tamanho especificado em chuck_len\n",
        "def random_chunk():\n",
        "    start_index = random.randint(0, file_len - chunk_len)\n",
        "    end_index = start_index + chunk_len + 1\n",
        "    return file[start_index:end_index]\n",
        "\n",
        "print(random_chunk())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Wqh8sI7gO3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converte string para uma lista de inteiros\n",
        "\n",
        "def char_tensor(string):\n",
        "    tensor = torch.zeros(len(string)).long()\n",
        "    for c in range(len(string)):\n",
        "      try:\n",
        "        tensor[c] = all_characters.index(string[c])\n",
        "      except:\n",
        "        print(c)\n",
        "        raise\n",
        "    return Variable(tensor)\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5YsB69SvstI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um 'exemplo' aleatório (um pedaço aleatório convertido para lista de inteiros)\n",
        "def random_training_set():    \n",
        "    chunk = random_chunk()\n",
        "    inp = char_tensor(chunk[:-1])\n",
        "    target = char_tensor(chunk[1:])\n",
        "    return inp, target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVAe8dOmxS5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        \n",
        "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
        "        self.decoder = nn.Linear(hidden_size, output_size)\n",
        "    \n",
        "    def forward(self, input, hidden):\n",
        "        input = self.encoder(input.view(1, -1))\n",
        "        output, hidden = self.gru(input.view(1, 1, -1), hidden)\n",
        "        decoded_output = self.decoder(output.view(1, -1))\n",
        "        return decoded_output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return Variable(torch.zeros(self.n_layers, 1, self.hidden_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfJ5i2Cb1Orb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gera um texto iniciando com \"prime_str\" de tamanho \"predict_len\" e variação definida por \"temperature\"\n",
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "    hidden = rnn.init_hidden().cuda()\n",
        "    prime_input = char_tensor(prime_str).cuda()\n",
        "    predicted = prime_str\n",
        "\n",
        "    # prime_str é o texto inicial que o gerado irá completar\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = rnn(prime_input[p], hidden)\n",
        "    inp = prime_input[-1]\n",
        "    \n",
        "    for p in range(predict_len):\n",
        "        output, hidden = rnn(inp, hidden)\n",
        "        \n",
        "        # Usa a temperatura para amostrar a distribuição e escolher a saída probabilísticamente\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "        \n",
        "        # Adiciona o caracter predito à string de saída\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = char_tensor(predicted_char).cuda()\n",
        "\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIrgoMRw6-Pm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treina sobre um exemplo (i.e. uma amostragem do texto)\n",
        "\n",
        "def train(inp, target):\n",
        "    hidden = rnn.init_hidden()\n",
        "    rnn.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    inp = inp.cuda()\n",
        "    hidden = hidden.cuda()\n",
        "    for c in range(chunk_len):\n",
        "        output, hidden = rnn(inp[c], hidden)\n",
        "        loss += loss_metric(output, target[c].unsqueeze(0))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.data.item() / chunk_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmzVCPH2oxK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 50000\n",
        "print_every = 100\n",
        "hidden_size = 512\n",
        "n_layers = 2\n",
        "lr = 0.0005\n",
        "\n",
        "cuda = torch.device('cuda')\n",
        "\n",
        "rnn = RNN(n_characters, hidden_size, n_characters, n_layers)\n",
        "rnn.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
        "loss_metric = nn.CrossEntropyLoss()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    example = random_training_set()\n",
        "    loss = train(example[0].cuda(),example[1].cuda())       \n",
        "    loss_avg += loss\n",
        "\n",
        "    if epoch % print_every == 0:\n",
        "        print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / n_epochs * 100, loss))\n",
        "        print(evaluate('Os', 100), '\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQgGglFw5HYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Com a rede treinada, gerar um texto longo\n",
        "\n",
        "print(evaluate('O psicanalista de', 5500), '\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkXB6Dn_scZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}